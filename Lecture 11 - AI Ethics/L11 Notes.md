Weekly Quiz Answer
[[L11 Quiz Answers]]

# AI
Definition: Artificial intelligence (AI) is intelligence demonstrated by computers. Here, "Intelligence" encompasses the ability to learn and to reason, to generalize, and to infer meaning.

Some AI applications:
- Advanced web search engines (e.g., Google Search)
- Recommendation systems (used by YouTube, Amazon, and Netflix)
- Understanding human speech (e.g., Siri and Alexa)
- Self-driving cars (e.g., Waymo)
- Generative or creative tools (e.g., ChatGPT)
- Competing in strategic games (such as chess and Go)

#### AI Research discipline
- AI has been around for more than 70 years.
- People’s understanding of AI as a technology has been evolving.
- Today, when people talk about AI, they often refer to systems that make use of machine learning techniques.

## Categorization of AI
- Weak AI
	- refers to programs that demonstrate intelligence in performing specific tasks or solving particular problems within a limited domain
	- Examples:
		- Siri, Alexa, Spam filters, image recognition, recommendation systems, etc
- Strong AI
	- refers to programs that have human-level intelligence in the form of understanding, learning, and performing any intellectual task that a human being can do, across different domains. The development of strong AI has remained hypothetical and has not been achieved yet.
- Superintelligence
	- refers to AI systems that surpass human intelligence and therefore they are difficult for us to understand. They exhibit capabilities far beyond what humans can comprehend.

## Ethical Concerns of AI Use
- Privacy and surveillance
	- Surveillance technologies combined with AI such as facial recognition can pose significant privacy risks to individuals.
- Job displacement
	- AI has the potential to eliminate jobs which leads to concerns about unemployment and economic inequality.
- Misuse
	- Like other technologies, AI can be misused. For example, scammers can use the deepfake technology to impersonate other people and fool their relatives and friends into transferring money.
- Bias and fairness
	- Bias in training data can lead to biased predictions. Ensuring fairness in AI algorithms can be a significant ethical challenge.
- Accountability and responsibility
	- Take autonomous cars as an example. If an accident happens, should the owner of the car be responsible? Or the person in the driver’s seat, the manufacturer of the car, or other road users?
- Impact on learning
	- Over reliance on AI systems such as ChatGPT may prevent learners from acquiring critical thinking skills and the ability to summarize and synthesize contents.
- Polarization of political views
	- Users may only be recommended the same kind of news over and over again, resulting in an increasingly biased world view. Within a society, political views may become polarized, leading to divisions between groups.
- Ethical decision-making by AI
	- AI systems may face situations where ethical dilemmas arise. Determining how AI should be programmed to handle such scenarios is a complex ethical problem.


# Guidelines of AI Ethics
## Singapore's Model AI Governance Framework
2 guiding principles:
1. Organizations using AI in decision-making should ensure that the decision-making process is explainable, transparent and fair:
	- Organizations should strive to ensure that their use or application of AI is undertaken in a manner that reflects the objectives of these principles as far as possible. This helps build trust and confidence in AI.
2. AI Solutions should be human-centric:
	- In other words, the protection of the interests of human beings, including their well-being and safety, should be the primary considerations in the design, development and deployment of AI.

## European Commission's "Ethics Guidelines for Trustworthy AI"
- Applicable to different stakeholders partaking in AI systems' life cycle:
	- Developers
		- Should implement and apply the requirements to design and development processes;
	- Deployers
		- Should ensure that the systems they use and the products and services they offer meet the requirements;
	- End Users and the broader society
		- Should be informed about these requirements and able to request that they are upheld.

- The 7 Requirements:
	1. Human agency and oversight
		- AI systems should empower human beings, allowing them to make informed autonomous decisions. AI systems should not influence human behaviour through mechanisms such as unfair manipulation, deception, herding and conditioning.
		- Proper oversight mechanisms must be in place to maintain human control and ethical responsibility. There are three approaches to human oversight: ___human-in-the-loop, human-on-the-loop and human-out-of-the-loop___.
			- Humans-in-the-loop:
				- is the approach that requires human intervention in every decision of the system. When the number of transactions involved is high, however, this approach may be not be possible or desirable.
			- Humans-on-the-loop:
				- is the approach where humans have a more supervisory or oversight role. The system operates autonomously most of the time, but humans periodically review the system's outputs, monitor its performance, and intervene when necessary.
			- Humans-out-of-the-loop:
				- is the approach where the AI is given full control over the execution of decisions. Humans evaluate the overall performance of the system and decide whether or how it will be used in future.
	2. Technical robustness and safety
		- Output from AI systems needs to be accurate, reliable and reproducible. In addition, AI systems must be resilient to attacks on the data (e.g., data poisoning), the model (e.g., model leakage) and/or the underlying infrastructure. A fallback plan needs to be established in case something goes wrong.
	3. Privacy and data governance
		- This requires responsible management of data throughout the lifecycle of AI systems. Responsible management of data covers some of the PDPA obligations. In addition, protocols governing data access should be put in place to outline who has access to data and under what circumstances.
	4. Transparency
		- This requires that the behavior, decision-making process, and underlying mechanisms of AI systems are understandable and interpretable by human users. Transparency helps establish trust with users and allow them to make informed decisions regarding the adoption and use of AI.
		- The AI system should ideally be explainable. Even when an AI model cannot be explained, understanding and trust can still be built by explaining how predictions play a role in the decision-making process (Model Framework 2020, p. 44).
	
		- Example: Facebook:
			- Provides a general disclosure about its collection and use of data.
			- Publishes blogposts to discuss complex subjects.
			- Promotes a series of AI educational initiatives and campaigns to help users learn about AI.
			- Has implemented a “Why am I seeing this post?” feature to explain how users’ past interactions impacted the ranking of posts in News Feed.
	5. Diversity, non-discrimination and fairness
		- This requires AI systems to avoid unfair bias, foster diversity and ensure accessibility for users with different abilities.
			- Ensure that the training data encompass a wide range of demographic, cultural, and socio-economic characteristics.
			- Bias detection should also be applied to determine if results from AI systems are fair.
			- AI systems should be user-centric and designed in a way that allows all people to use the AI products or services, regardless of their age, gender, abilities or characteristics.
			  
		- Example: Pymetrics
			- Uses neuroscience insights and audited AI models to help evaluate job applicants in a predictive and less biased manner.
			- Ensure that the selection rate of a minority group is at least 80% of the selection rate for the majority group.
	6. Societal and environmental well-being
		- AI systems should be developed and deployed in a manner that is environmentally friendly. Their impact on education, work, entertainment and other aspects of our lives, should also be carefully considered.
	7. Accountability
		- Mechanisms should be put in place to ensure responsibility and accountability for AI systems and their outcomes. This involves establishing clear roles and responsibilities.
		
		- To ensure robust oversight, MasterCard established a Governance Council to review and approve the implementation of high-risk AI applications. MasterCard has defined clear roles and responsibilities, as shown below:
		- ![[Pasted image 20240731053315.png]]

### Implementation checklist
- The European Commission provides a checklist to help us implement these requirements.
- The checklist can be found here: [https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=68342](https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=68342)


# Use of Generative AI in Education
## ChatGPT
Chatbot created by OpenAI

- Fastest-growing user application in history
	- reaching 100 million active users within 2 months after its introduction
- Its performance in assessments varies across subjects
	- ![[Pasted image 20240731053531.png]]

- An interesting finding from Lo (2023) shows that ChatGPT performs well in tasks requiring critical and high-order thinking, but it does poorly in multiple-choice questions (often associated with low-order thinking).
	- ![[Pasted image 20240731053555.png]]


# Bloom's taxonomy
![[Pasted image 20240731053641.png]]


## Risk to Academic Integrity
- ChatGPT can demonstrate apparent high-order thinking (such as creativity) but this ability is limited by what it has been exposed to during training.
- The power of ChatGPT poses great risks to academic integrity:
	- We can require students to demonstrate an ability beyond what ChatGPT can achieve, but this may be too demanding.
	- We can give guidelines on or even ban the use of ChatGPT. But if there is no effective way to enforce the rules, we would simply be putting the rule-abiding individuals in a disadvantaged position.
	- We can rely more on face-to-face exams, but this way not be in line with authentic learning.

## Advantages of ChatGPT
Supporters argue that, instead of discouraging its use, we should teach students how to use it in a responsible manner. Furthermore, the technology offers the following advantages:
- Facilitates personalized learning
	- ChatGPT returns information based on an individual student’s current level of understanding
- Time-savings
	- ChatGPT can save students time by providing quick answers to their questions
- Support for Non-native speakers of English
	- ChatGPT makes learning fairer for students whose first language is not English. With ChatGPT, they can now focus on content rather than spending extra time on translation.
- Sometimes ChatGPT gives wrong answers
	- Some educators have argued that this helps students understand the importance of critical thinking.

## Disadvantages of ChatGPT
•Aside from the main concern related to academic integrity, factors discouraging the use of ChatGPT include:
- Potential bias
	- When asked to name the top 10 philosophers in human history, this is the list ChatGPT gave me (on 7 July 2023):
	- ![[Pasted image 20240731054009.png]]
- Generated answers may not be up-to-date
	- The data used to train ChatGPT was only up to September 2021.
- Sometimes, ChatGPT gives wrong answers
	- Students who do not have very strong critical thinking skills make wrong decisions based on the wrong answers.